{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'experimenter.utils.text' from '../experimenter/utils/text.py'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import importlib\n",
    "import experimenter\n",
    "from experimenter.utils import text\n",
    "\n",
    "importlib.reload(experimenter)\n",
    "importlib.reload(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will create train, dev, test(s) splits\n",
      "Total params: 2245\n",
      "Starting training:\n",
      "Epoch: 0: Train loss (last batch): 4.161691665649414, validation loss: 81.64664459228516\n",
      "Best model saved at: model.state\n",
      "Epoch: 2: Train loss (last batch): 2.151963233947754, validation loss: 38.215728759765625\n",
      "Best model saved at: model.state\n",
      "tensor(38.0964, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 3,\n",
       " 'experiment_output_path': 'final_training.json',\n",
       " 'log_interval': 2,\n",
       " 'model_path': 'model.state',\n",
       " 'processor': {'module': 'experimenter.utils.data',\n",
       "  'class': 'PairStanceProvider',\n",
       "  'params': {'input_path': '/Users/jkhouja/workspace/repo/arabic_media/data/pairs/batch_0_to_15000_pairs_sep__score_10_ngrams_2_3_4_5_6.csv',\n",
       "   'seq_len': [[20, 20], [1], [1]],\n",
       "   'batch_size': 20,\n",
       "   'splits': [0.1, 0.1, 0.1, 0.7],\n",
       "   'drop_last': 'False',\n",
       "   'shuffle': 'True',\n",
       "   'vocab_path': 'vocab.json',\n",
       "   'vocab_size': 75}},\n",
       " 'model': {'module': 'experimenter.utils.modeling',\n",
       "  'class': 'RNNPairModel',\n",
       "  'params': {'embedding_dim': 8,\n",
       "   'hidden_dim': 10,\n",
       "   'num_classes': 75,\n",
       "   'dropout': 0,\n",
       "   'max_seq_len': [20, 20]},\n",
       "  'model': RNNPairModel(\n",
       "    (emb): Embedding(75, 8, padding_idx=0)\n",
       "    (lstm): LSTM(8, 10, batch_first=True)\n",
       "    (linear): Linear(in_features=10, out_features=75, bias=True)\n",
       "    (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )},\n",
       " 'evaluator': {'module': 'experimenter.evaluation',\n",
       "  'class': 'ListEvaluator',\n",
       "  'params': {'loss_f': [{'module': 'torch.nn',\n",
       "     'class': 'CrossEntropyLoss',\n",
       "     'params': {'reduction': 'none'}}]}},\n",
       " 'optimizer': {'module': 'torch.optim',\n",
       "  'class': 'Adam',\n",
       "  'params': {'params': <generator object Module.parameters at 0x1233281d0>,\n",
       "   'lr': 0.001}},\n",
       " 'results': {'during_training': {'0': {'train_loss': 4.161691665649414,\n",
       "    'val_loss': 81.64664459228516},\n",
       "   '2': {'train_loss': 2.151963233947754, 'val_loss': 38.215728759765625}},\n",
       "  'best': {'train_loss': 2.151963233947754, 'val_loss': 38.215728759765625}}}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair stance classification\n",
    "import pandas as pd\n",
    "from experimenter import evaluation\n",
    "from experimenter.utils import modeling, training, data\n",
    "importlib.reload(modeling)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(training)\n",
    "importlib.reload(data)\n",
    "\n",
    "configs = {\"epochs\": 3,\n",
    "           \"experiment_output_path\": \"final_training.json\", \n",
    "           \"log_interval\": 2, \"model_path\": \"model.state\", \n",
    "           \"processor\": {\n",
    "                \"module\": \"experimenter.utils.data\",\n",
    "                \"class\": \"PairStanceProvider\",\n",
    "                \"params\":{\"input_path\": \"/Users/jkhouja/workspace/repo/arabic_media/data/pairs/batch_0_to_15000_pairs_sep__score_10_ngrams_2_3_4_5_6.csv\",\n",
    "                          \"seq_len\": [[20,20],[1],[1]], \"batch_size\": 20, \"splits\": [.1, .1, .1, .7], \"drop_last\":\"False\",  \"shuffle\": \"True\", \"vocab_path\": \"vocab.json\"}},\n",
    "           \"model\":{\n",
    "                \"module\": \"experimenter.utils.modeling\",\n",
    "                \"class\": \"RNNPairModel\",\n",
    "                \"params\":{\"embedding_dim\": 8, \"hidden_dim\": 10, \"num_classes\": {\"eval\":1, \"value\":\"config['processor']['params']['vocab_size']\"}, \"dropout\": 0, \"max_seq_len\": {\"eval\": 1, \"value\": \"config['processor']['params']['seq_len'][0]\"}}},\n",
    "           \n",
    "            \"evaluator\":{\n",
    "                \"module\": \"experimenter.evaluation\",\n",
    "                \"class\": \"ListEvaluator\",\n",
    "                \"params\": {\"loss_f\": [{\"module\": 'torch.nn', \"class\": 'CrossEntropyLoss', \"params\": {'reduction': 'none'}}]}},\n",
    "           \"optimizer\":{\n",
    "                \"module\": \"torch.optim\",\n",
    "                \"class\": \"Adam\",\n",
    "                \"params\":{\n",
    "                    \"params\": {\n",
    "                    \"eval\": 1,\n",
    "                    \"value\": \"config['model']['model'].parameters()\"},\n",
    "                'lr':  0.001}}\n",
    "           }\n",
    "\n",
    "\n",
    "trainer = training.BasicTrainer(configs)\n",
    "trainer.train_model()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on unlabled data\n",
    "\n",
    "limit = 10\n",
    "unlabeled_data = [[\"عبر رجل\", \"قال رجل\"]] * 7\n",
    "\n",
    "pred = trainer.predict(unlabeled_data, decode=False)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training:\n",
      "Epoch: 2: Train loss (last batch): 0.7104984521865845, validation loss: 28.14354133605957\n",
      "Best model saved at: model.state\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epochs': 3,\n",
       " 'experiment_output_path': 'final_training.json',\n",
       " 'log_interval': 2,\n",
       " 'model_path': 'model.state',\n",
       " 'processor': {'module': 'experimenter.utils.data',\n",
       "  'class': 'PairStanceProvider',\n",
       "  'params': {'input_path': '/Users/jkhouja/workspace/repo/arabic_media/data/pairs/batch_0_to_15000_pairs_sep__score_10_ngrams_2_3_4_5_6.csv',\n",
       "   'seq_len': [[20, 20], [1], [1]],\n",
       "   'batch_size': 20,\n",
       "   'splits': [0.1, 0.1, 0.1, 0.7],\n",
       "   'drop_last': 'False',\n",
       "   'shuffle': 'True',\n",
       "   'vocab_path': 'vocab.json',\n",
       "   'vocab_size': 75}},\n",
       " 'model': {'module': 'experimenter.utils.modeling',\n",
       "  'class': 'RNNPairModel',\n",
       "  'params': {'embedding_dim': 8,\n",
       "   'hidden_dim': 10,\n",
       "   'num_classes': 75,\n",
       "   'dropout': 0,\n",
       "   'max_seq_len': [20, 20]},\n",
       "  'model': RNNPairModel(\n",
       "    (emb): Embedding(75, 8, padding_idx=0)\n",
       "    (lstm): LSTM(8, 10, batch_first=True)\n",
       "    (linear): Linear(in_features=10, out_features=75, bias=True)\n",
       "    (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )},\n",
       " 'evaluator': {'module': 'experimenter.evaluation',\n",
       "  'class': 'ListEvaluator',\n",
       "  'params': {'loss_f': [{'module': 'torch.nn',\n",
       "     'class': 'CrossEntropyLoss',\n",
       "     'params': {'reduction': 'none'}}]}},\n",
       " 'optimizer': {'module': 'torch.optim',\n",
       "  'class': 'Adam',\n",
       "  'params': {'params': <generator object Module.parameters at 0x121fb0c50>,\n",
       "   'lr': 0.001}},\n",
       " 'results': {'during_training': {'2': {'train_loss': 0.7104984521865845,\n",
       "    'val_loss': 28.14354133605957}},\n",
       "  'best': {'train_loss': 0.7104984521865845, 'val_loss': 28.14354133605957}}}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on unlabled data\n",
    "eval_data = trainer.processor.get_data()[1]\n",
    "limit = 10\n",
    "unlabeled_data = [[\"عبر رجل\", \"قال رجل\"]] * 7\n",
    "\n",
    "pred = trainer.predict(unlabeled_data)\n",
    "\n",
    "# Get entropy, Select data\n",
    "\n",
    "entr = get_ent(pred_entr)\n",
    "\n",
    "selected_idx = np.argmax(entr, limit)\n",
    "\n",
    "\n",
    "selected_data = unlabeled_data[selected_idx]\n",
    "\n",
    "# Get labeles\n",
    "selected_data = [[[\"قال رجل\", \"قال رجل\"],[['agree']],[1]]]*2\n",
    "\n",
    "#Retrain\n",
    "this_data = trainer.processor(selected_data, data_type='full', list_input= True, as_batches=True)\n",
    "trainer.train_model([this_data, eval_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "importlib.reload(data)\n",
    "\n",
    "class mydict(dict):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(mydict, self).__init__(*args, **kwargs)\n",
    "        self.len = 6\n",
    "    pass\n",
    "\n",
    "    \n",
    "\n",
    "data_as_dict = mydict({'in':np.zeros(10), 'out':np.ones(10)})\n",
    "data_as_dict = data.DictDataset(data_as_dict)\n",
    "d = torch.utils.data.DataLoader(dataset=data_as_dict, batch_size=2, drop_last=False, shuffle=False)\n",
    "for b in d:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_dict = mydict({'in':np.zeros(10), 'out':np.ones(10)})\n",
    "s = data_as_dict.__class__()\n",
    "assert isinstance(s, dict)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__main__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-6714459d4612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'in'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m__main__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__main__' is not defined"
     ]
    }
   ],
   "source": [
    "s = mydict({'in':np.zeros(10), 'out':np.ones(10)})\n",
    "__main__.mydict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.3336, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = trainer.evaluate([[[\"قال رجل\", \"قال رجل\"],[['agree']],[1]],[[\"قال رجل\", \"قال رجل\"],[['agreasdfde']],[1]]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1286a5a50>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.processor([[\"قال رجل\", \"قال رجل\"],[['agree']],[1]], data_type='full', as_batches=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agree', 'agree', 'agree', 'agree', 'agree', 'agree', 'agree']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = trainer.predict([[\"عبر رجل\", \"قال رجل\"]] * 7)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'argmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-640154111aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# batch_size = 1 or last batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-640154111aff>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# batch_size = 1 or last batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'argmax'"
     ]
    }
   ],
   "source": [
    "t = trainer.predict([[\"عبر رجل\", \"قال رجل\"]] * 7)\n",
    "#len(t[0][0])\n",
    "res = []\n",
    "for b in t:\n",
    "    try:\n",
    "        res.extend([s.argmax(dim=1).tolist() for s in b])\n",
    "    except IndexError as e:\n",
    "        # batch_size = 1 or last batch\n",
    "        res.extend([[s.argmax().tolist() for s in b]])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index out of range: Tried to access index 75 out of table with 74 rows. at ../aten/src/TH/generic/THTensorEvenMoreMath.cpp:418",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-9207d9443ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hi there\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"man\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/repo/latynt/experimenter/experimenter/utils/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_as_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#which part of the output?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m#decoded = self.processor.decode(res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/repo/latynt/experimenter/experimenter/utils/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_batch, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# second item in inps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0ms1_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0ms2_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range: Tried to access index 75 out of table with 74 rows. at ../aten/src/TH/generic/THTensorEvenMoreMath.cpp:418"
     ]
    }
   ],
   "source": [
    "t = trainer.predict([[\"hi there\", \"man\"]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.processor([[\"hi there\", \"man\"]] * 4, list_input= True, as_batches=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = trainer.processor([[\"hi_there man_\", \"test this\"]] * 3, list_input=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['hi', 'by']\n",
    "tuple(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will create train, dev, test(s) splits\n",
      "Total params: 2245\n",
      "Starting training:\n",
      "Epoch: 0: Train loss (last batch): 4.127970218658447, validation loss: 82.26912689208984\n",
      "Best model saved at: model.state\n",
      "Epoch: 2: Train loss (last batch): 1.525651454925537, validation loss: 31.06138038635254\n",
      "Best model saved at: model.state\n",
      "tensor(31.1143, grad_fn=<DivBackward0>)\n",
      "Traceback (most recent call last):\n",
      "  File \"../run.py\", line 23, in <module>\n",
      "    config = train_model()\n",
      "NameError: name 'train_model' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python ../run.py --config_file \"../local/pairs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(s):\n",
    "    tokenizer = text.tokenizer(sep='')\n",
    "    cleaner = text.clean_text('_')\n",
    "    #cleaner2 = text.clean_text('h')\n",
    "    enc = text.encoder(update_vocab=True, no_special_chars=False)\n",
    "    pipeline = text.chainer(funcs=[cleaner, tokenizer, enc])\n",
    "    res = []\n",
    "    for inp in s:\n",
    "        proc = pipeline(inp, list_input=False)\n",
    "        res.append([[proc, proc], [[2],[1]], [1, 100]])\n",
    "    return res, enc #need to fix returned objects it's a mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.argmax(model(iter(d1).next())[0][0].detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(iter(d1).next())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = a([\"hi_there man_\", \"how are you?\"], list_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chainer():\n",
    "    tokenizer = text.tokenizer(sep=' ')\n",
    "    enc = text.encoder(update_vocab=True)\n",
    "    chain = text.chainer(funcs=[tokenizer, enc, enc.decode, tokenizer.detokenize])\n",
    "    \n",
    "    inp = \"مرحبا هنا\"\n",
    "    assert inp == chain(inp, list_input=False)\n",
    "    \n",
    "    inp = [\"hi_there man_\", \"how are you?\"]\n",
    "    assert inp == chain(inp, list_input=True)\n",
    "\n",
    "test_chainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.list_applyer\n",
    "cleaner = text.clean_text('_')\n",
    "\n",
    "cleaner(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class a:\n",
    "    #self.b = \"hi\"\n",
    "    def __init__(self):\n",
    "        self.b = \"hi\"\n",
    "    def test(self, text=b):\n",
    "        print(text)\n",
    "tryme = a()\n",
    "tryme.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
