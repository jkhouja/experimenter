{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will create train, dev, test(s) splits\n",
      "Total params: 12893\n",
      "Will create train, dev, test(s) splits\n",
      "Total params: 12893\n",
      "Starting training:\n",
      "Epoch: 1: Train loss (last batch): 1.0959333181381226, validation loss: 1.0971243381500244\n",
      "Best model saved at: model.state\n",
      "Epoch: 2: Train loss (last batch): 1.1127394437789917, validation loss: 1.0927706956863403\n",
      "Best model saved at: model.state\n",
      "Epoch: 3: Train loss (last batch): 1.2162951231002808, validation loss: 1.0798826217651367\n",
      "Best model saved at: model.state\n",
      "Epoch: 4: Train loss (last batch): 1.1723943948745728, validation loss: 1.0638456344604492\n",
      "Best model saved at: model.state\n",
      "Epoch: 5: Train loss (last batch): 1.0028953552246094, validation loss: 1.0499619245529175\n",
      "Best model saved at: model.state\n",
      "Test loss: 1.0245028734207153\n",
      "Starting training:\n",
      "Epoch: 1: Train loss (last batch): 1.0776337385177612, validation loss: 1.0983085632324219\n",
      "Best model saved at: model.state\n",
      "Epoch: 2: Train loss (last batch): 1.1173642873764038, validation loss: 1.087583303451538\n",
      "Best model saved at: model.state\n",
      "Epoch: 3: Train loss (last batch): 1.0278970003128052, validation loss: 1.0723031759262085\n",
      "Best model saved at: model.state\n",
      "Epoch: 4: Train loss (last batch): 1.123039722442627, validation loss: 1.06743586063385\n",
      "Best model saved at: model.state\n",
      "Epoch: 5: Train loss (last batch): 1.1939892768859863, validation loss: 1.2348051071166992\n",
      "Test loss: 1.1962709426879883\n"
     ]
    }
   ],
   "source": [
    "# pair stance classification\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "import experimenter\n",
    "from experimenter import evaluation\n",
    "from experimenter.utils import modeling, training, data, text\n",
    "importlib.reload(experimenter)\n",
    "importlib.reload(text)\n",
    "importlib.reload(modeling)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(training)\n",
    "importlib.reload(data)\n",
    "\n",
    "configs = {\"epochs\": 5,\n",
    "           \"experiment_output_path\": \"final_training.json\", \n",
    "           \"log_interval\": 1, \"model_path\": \"model.state\", \n",
    "           \"processor\": {\n",
    "                \"module\": \"experimenter.utils.data\",\n",
    "                \"class\": \"PairStanceProvider\",\n",
    "                \"params\":{\"input_path\": \"/Users/jkhouja/workspace/repo/arabic_media/data/pairs/batch_0_to_15000_pairs_eq_weight_random.csv\",\n",
    "                          \"seq_len\": {'inp':[50,50], 'label':[1],'mask':[1]}, \"batch_size\": 4, \"splits\": [.1, .2, .1, .6], \"drop_last\":\"False\",  \"shuffle\": \"True\", \"vocab_path\": \"vocab.json\"}},\n",
    "           \"model\":{\n",
    "                \"module\": \"experimenter.utils.modeling\",\n",
    "                \"class\": \"RNNPairModel\",\n",
    "                \"params\":{\"embedding_dim\": 8, \"hidden_dim\": 50, \"num_classes\": 3, \"dropout\": 0, \"max_seq_len\": {\"eval\": 1, \"value\": \"config['processor']['params']['seq_len']['inp'][0]\"}}},\n",
    "           \n",
    "            \"evaluator\":{\n",
    "                \"module\": \"experimenter.evaluation\",\n",
    "                \"class\": \"ListEvaluator\",\n",
    "                \"params\": {\"loss_f\": [{\"module\": 'torch.nn', \"class\": 'CrossEntropyLoss', \"params\": {'reduction': 'none'}}]}},\n",
    "            \"optimizer\":{\n",
    "                \"module\": \"torch.optim\",\n",
    "                \"class\": \"Adam\",\n",
    "                \"params\":{\n",
    "                    \"params\": {\n",
    "                    \"eval\": 1,\n",
    "                    \"value\": \"config['model']['model'].parameters()\"},\n",
    "                'lr':  0.001}}\n",
    "           }\n",
    "\n",
    "\n",
    "configs2 = {\"epochs\": 5,\n",
    "           \"experiment_output_path\": \"final_training.json\", \n",
    "           \"log_interval\": 1, \"model_path\": \"model.state\", \n",
    "           \"processor\": {\n",
    "                \"module\": \"experimenter.utils.data\",\n",
    "                \"class\": \"PairStanceProvider\",\n",
    "                \"params\":{\"input_path\": \"/Users/jkhouja/workspace/repo/arabic_media/data/pairs/batch_0_to_15000_pairs_eq_weight_random.csv\",\n",
    "                          \"seq_len\": {'inp':[50,50], 'label':[1],'mask':[1]}, \"batch_size\": 4, \"splits\": [.1, .2, .1, .6], \"drop_last\":\"False\",  \"shuffle\": \"True\", \"vocab_path\": \"vocab.json\"}},\n",
    "           \"model\":{\n",
    "                \"module\": \"experimenter.utils.modeling\",\n",
    "                \"class\": \"RNNPairModel\",\n",
    "                \"params\":{\"embedding_dim\": 8, \"hidden_dim\": 50, \"num_classes\": 3, \"dropout\": 0, \"max_seq_len\": {\"eval\": 1, \"value\": \"config['processor']['params']['seq_len']['inp'][0]\"}}},\n",
    "           \n",
    "            \"evaluator\":{\n",
    "                \"module\": \"experimenter.evaluation\",\n",
    "                \"class\": \"ListEvaluator\",\n",
    "                \"params\": {\"loss_f\": [{\"module\": 'torch.nn', \"class\": 'CrossEntropyLoss', \"params\": {'reduction': 'none'}}]}},\n",
    "            \"optimizer\":{\n",
    "                \"module\": \"torch.optim\",\n",
    "                \"class\": \"Adam\",\n",
    "                \"params\":{\n",
    "                    \"params\": {\n",
    "                    \"eval\": 1,\n",
    "                    \"value\": \"config['model']['model'].parameters()\"},\n",
    "                'lr':  0.001}}\n",
    "           }\n",
    "\n",
    "#unlabeled_data = [{'inp':[\"يالت رجل\", \"قال رجلي\"],'label':[['agree']],'mask':[1]}]*10\n",
    "\n",
    "\n",
    "# Initialize two models\n",
    "trainer_smart = training.BasicTrainer(configs)\n",
    "trainer_random = training.BasicTrainer(configs2)\n",
    "\n",
    "# Initialize data from file\n",
    "\n",
    "val_data = trainer_smart.processor.get_data()[1]\n",
    "test_data = trainer_smart.processor.get_data()[2]\n",
    "initial_data = trainer_smart.processor.get_data()[0]\n",
    "\n",
    "unlabeled_data = trainer_smart.processor.decode(trainer_smart.processor.data_raw[3], list_input=True)\n",
    "\n",
    "res_smart = trainer_smart.train_model([initial_data, val_data, test_data])\n",
    "res_random = trainer_random.train_model([initial_data, val_data, test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "1.4463678059057392\n",
      "Remaining data before / after filtering the learned batch\n",
      "5052\n",
      "4852\n",
      "Starting training:\n",
      "Epoch: 11: Train loss (last batch): 1.0623605251312256, validation loss: 1.0581321716308594\n",
      "Best model saved at: model.state\n",
      "Epoch: 12: Train loss (last batch): 0.7871716618537903, validation loss: 1.0428305864334106\n",
      "Best model saved at: model.state\n",
      "Epoch: 13: Train loss (last batch): 1.1186940670013428, validation loss: 1.0667556524276733\n",
      "Epoch: 14: Train loss (last batch): 1.3207297325134277, validation loss: 1.088484525680542\n",
      "Epoch: 15: Train loss (last batch): 1.049099326133728, validation loss: 1.0591458082199097\n",
      "Test loss: 1.0410854816436768\n",
      "Starting training:\n",
      "Epoch: 11: Train loss (last batch): 0.9175735712051392, validation loss: 1.0657908916473389\n",
      "Best model saved at: model.state\n",
      "Epoch: 12: Train loss (last batch): 1.0900952816009521, validation loss: 1.0391796827316284\n",
      "Best model saved at: model.state\n",
      "Epoch: 13: Train loss (last batch): 0.9136359691619873, validation loss: 1.0532846450805664\n",
      "Epoch: 14: Train loss (last batch): 0.916773796081543, validation loss: 1.1083197593688965\n",
      "Epoch: 15: Train loss (last batch): 0.9679549336433411, validation loss: 1.062324047088623\n",
      "Test loss: 1.0580006837844849\n",
      "step 1\n",
      "1.38206908893295\n",
      "Remaining data before / after filtering the learned batch\n",
      "4852\n",
      "4652\n",
      "Starting training:\n",
      "Epoch: 16: Train loss (last batch): 1.1189956665039062, validation loss: 1.0685073137283325\n",
      "Best model saved at: model.state\n",
      "Epoch: 17: Train loss (last batch): 0.9065014123916626, validation loss: 1.056923747062683\n",
      "Best model saved at: model.state\n",
      "Epoch: 18: Train loss (last batch): 1.2434639930725098, validation loss: 1.0566821098327637\n",
      "Best model saved at: model.state\n",
      "Epoch: 19: Train loss (last batch): 0.9182854890823364, validation loss: 1.0448863506317139\n",
      "Best model saved at: model.state\n",
      "Epoch: 20: Train loss (last batch): 1.1181001663208008, validation loss: 1.0406386852264404\n",
      "Best model saved at: model.state\n",
      "Test loss: 1.0372388362884521\n",
      "Starting training:\n",
      "Epoch: 16: Train loss (last batch): 0.9485210180282593, validation loss: 1.055065393447876\n",
      "Best model saved at: model.state\n",
      "Epoch: 17: Train loss (last batch): 0.7836827635765076, validation loss: 1.0603671073913574\n",
      "Epoch: 18: Train loss (last batch): 0.6406785845756531, validation loss: 1.0549569129943848\n",
      "Best model saved at: model.state\n",
      "Epoch: 19: Train loss (last batch): 0.8027253150939941, validation loss: 1.070547342300415\n",
      "Epoch: 20: Train loss (last batch): 0.7191056609153748, validation loss: 1.1182302236557007\n",
      "Test loss: 1.1129086017608643\n",
      "step 2\n",
      "1.4244890975058873\n",
      "Remaining data before / after filtering the learned batch\n",
      "4652\n",
      "4452\n",
      "Starting training:\n",
      "Epoch: 21: Train loss (last batch): 0.887336015701294, validation loss: 1.0367839336395264\n",
      "Best model saved at: model.state\n",
      "Epoch: 22: Train loss (last batch): 1.700872778892517, validation loss: 1.0353449583053589\n",
      "Best model saved at: model.state\n",
      "Epoch: 23: Train loss (last batch): 1.0598227977752686, validation loss: 1.037508487701416\n",
      "Epoch: 24: Train loss (last batch): 0.6425461769104004, validation loss: 1.0609575510025024\n",
      "Epoch: 25: Train loss (last batch): 0.8147274851799011, validation loss: 1.057183027267456\n",
      "Test loss: 1.0293245315551758\n",
      "Starting training:\n",
      "Epoch: 21: Train loss (last batch): 1.581282615661621, validation loss: 1.0483531951904297\n",
      "Best model saved at: model.state\n",
      "Epoch: 22: Train loss (last batch): 1.1523157358169556, validation loss: 1.0490975379943848\n",
      "Epoch: 23: Train loss (last batch): 0.728576123714447, validation loss: 1.0555427074432373\n",
      "Epoch: 24: Train loss (last batch): 0.9184376001358032, validation loss: 1.0605363845825195\n",
      "Epoch: 25: Train loss (last batch): 1.4234167337417603, validation loss: 1.1444568634033203\n",
      "Test loss: 1.1540645360946655\n",
      "step 3\n",
      "1.3539831780538807\n",
      "Remaining data before / after filtering the learned batch\n",
      "4452\n",
      "4252\n",
      "Starting training:\n",
      "Epoch: 26: Train loss (last batch): 1.0146806240081787, validation loss: 1.0480296611785889\n",
      "Best model saved at: model.state\n",
      "Epoch: 27: Train loss (last batch): 0.8028432130813599, validation loss: 1.0411734580993652\n",
      "Best model saved at: model.state\n",
      "Epoch: 28: Train loss (last batch): 0.8426177501678467, validation loss: 1.0547993183135986\n",
      "Epoch: 29: Train loss (last batch): 1.3315198421478271, validation loss: 1.0865635871887207\n",
      "Epoch: 30: Train loss (last batch): 0.632735550403595, validation loss: 1.0776888132095337\n",
      "Test loss: 1.0302448272705078\n",
      "Starting training:\n",
      "Epoch: 26: Train loss (last batch): 1.2227954864501953, validation loss: 1.0606178045272827\n",
      "Best model saved at: model.state\n",
      "Epoch: 27: Train loss (last batch): 0.8665452003479004, validation loss: 1.088058352470398\n",
      "Epoch: 28: Train loss (last batch): 0.8043904304504395, validation loss: 1.071440577507019\n",
      "Epoch: 29: Train loss (last batch): 1.3654265403747559, validation loss: 1.0667750835418701\n",
      "Epoch: 30: Train loss (last batch): 0.683922529220581, validation loss: 1.0966410636901855\n",
      "Test loss: 1.1328626871109009\n",
      "step 4\n",
      "1.3022707130495343\n",
      "Remaining data before / after filtering the learned batch\n",
      "4252\n",
      "4052\n",
      "Starting training:\n",
      "Epoch: 31: Train loss (last batch): 1.4126191139221191, validation loss: 1.0514800548553467\n",
      "Best model saved at: model.state\n",
      "Epoch: 32: Train loss (last batch): 0.7288591861724854, validation loss: 1.0232900381088257\n",
      "Best model saved at: model.state\n",
      "Epoch: 33: Train loss (last batch): 1.1392401456832886, validation loss: 1.0322906970977783\n",
      "Epoch: 34: Train loss (last batch): 1.0369181632995605, validation loss: 1.0408066511154175\n",
      "Epoch: 35: Train loss (last batch): 0.9922736883163452, validation loss: 1.0423856973648071\n",
      "Test loss: 1.0337517261505127\n",
      "Starting training:\n",
      "Epoch: 31: Train loss (last batch): 1.2288153171539307, validation loss: 1.0651389360427856\n",
      "Best model saved at: model.state\n",
      "Epoch: 32: Train loss (last batch): 1.1433689594268799, validation loss: 1.0513683557510376\n",
      "Best model saved at: model.state\n",
      "Epoch: 33: Train loss (last batch): 0.8266544938087463, validation loss: 1.0444252490997314\n",
      "Best model saved at: model.state\n",
      "Epoch: 34: Train loss (last batch): 1.0492926836013794, validation loss: 1.0839295387268066\n",
      "Epoch: 35: Train loss (last batch): 0.820056140422821, validation loss: 1.0886927843093872\n",
      "Test loss: 1.1261471509933472\n",
      "step 5\n",
      "1.3391012990209195\n",
      "Remaining data before / after filtering the learned batch\n",
      "4052\n",
      "3852\n",
      "Starting training:\n",
      "Epoch: 36: Train loss (last batch): 1.0320680141448975, validation loss: 1.0291532278060913\n",
      "Best model saved at: model.state\n",
      "Epoch: 37: Train loss (last batch): 1.2148253917694092, validation loss: 1.0175738334655762\n",
      "Best model saved at: model.state\n",
      "Epoch: 38: Train loss (last batch): 0.9755659103393555, validation loss: 1.0366709232330322\n",
      "Epoch: 39: Train loss (last batch): 0.6312243342399597, validation loss: 1.03802490234375\n",
      "Epoch: 40: Train loss (last batch): 1.0244741439819336, validation loss: 1.081958532333374\n",
      "Test loss: 1.070029377937317\n",
      "Starting training:\n",
      "Epoch: 36: Train loss (last batch): 1.4246127605438232, validation loss: 1.0604970455169678\n",
      "Best model saved at: model.state\n",
      "Epoch: 37: Train loss (last batch): 0.7153793573379517, validation loss: 1.0429418087005615\n",
      "Best model saved at: model.state\n",
      "Epoch: 38: Train loss (last batch): 0.8627102971076965, validation loss: 1.0565204620361328\n",
      "Epoch: 39: Train loss (last batch): 0.8533084392547607, validation loss: 1.0458333492279053\n",
      "Epoch: 40: Train loss (last batch): 0.5927283763885498, validation loss: 1.054093837738037\n",
      "Test loss: 1.0683168172836304\n",
      "step 6\n",
      "1.2924677676357585\n",
      "Remaining data before / after filtering the learned batch\n",
      "3852\n",
      "3652\n",
      "Starting training:\n",
      "Epoch: 41: Train loss (last batch): 0.8066275715827942, validation loss: 1.0894639492034912\n",
      "Best model saved at: model.state\n",
      "Epoch: 42: Train loss (last batch): 0.832968533039093, validation loss: 1.059286117553711\n",
      "Best model saved at: model.state\n",
      "Epoch: 43: Train loss (last batch): 0.6269853711128235, validation loss: 1.0258805751800537\n",
      "Best model saved at: model.state\n",
      "Epoch: 44: Train loss (last batch): 0.8821024894714355, validation loss: 1.0154292583465576\n",
      "Best model saved at: model.state\n",
      "Epoch: 45: Train loss (last batch): 0.8464297652244568, validation loss: 1.0149935483932495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: model.state\n",
      "Test loss: 0.9901295900344849\n",
      "Starting training:\n",
      "Epoch: 41: Train loss (last batch): 1.2643591165542603, validation loss: 1.0451629161834717\n",
      "Best model saved at: model.state\n",
      "Epoch: 42: Train loss (last batch): 1.170201063156128, validation loss: 1.052954912185669\n",
      "Epoch: 43: Train loss (last batch): 0.956839919090271, validation loss: 1.0390136241912842\n",
      "Best model saved at: model.state\n",
      "Epoch: 44: Train loss (last batch): 1.3444180488586426, validation loss: 1.0519754886627197\n",
      "Epoch: 45: Train loss (last batch): 0.9354345798492432, validation loss: 1.061521053314209\n",
      "Test loss: 1.0727882385253906\n",
      "step 7\n",
      "1.3193084428125657\n",
      "Remaining data before / after filtering the learned batch\n",
      "3652\n",
      "3452\n",
      "Starting training:\n",
      "Epoch: 46: Train loss (last batch): 0.9979891777038574, validation loss: 1.013409972190857\n",
      "Best model saved at: model.state\n",
      "Epoch: 47: Train loss (last batch): 1.0384202003479004, validation loss: 1.0270806550979614\n",
      "Epoch: 48: Train loss (last batch): 0.9247334003448486, validation loss: 1.009764552116394\n",
      "Best model saved at: model.state\n",
      "Epoch: 49: Train loss (last batch): 0.6837278604507446, validation loss: 1.045725703239441\n",
      "Epoch: 50: Train loss (last batch): 0.789980947971344, validation loss: 1.032309651374817\n",
      "Test loss: 1.0286307334899902\n",
      "Starting training:\n",
      "Epoch: 46: Train loss (last batch): 1.3269755840301514, validation loss: 1.0603642463684082\n",
      "Best model saved at: model.state\n",
      "Epoch: 47: Train loss (last batch): 0.9808925986289978, validation loss: 1.0559049844741821\n",
      "Best model saved at: model.state\n",
      "Epoch: 48: Train loss (last batch): 0.8008478283882141, validation loss: 1.0520098209381104\n",
      "Best model saved at: model.state\n",
      "Epoch: 49: Train loss (last batch): 0.907310426235199, validation loss: 1.0645307302474976\n",
      "Epoch: 50: Train loss (last batch): 0.41877052187919617, validation loss: 1.0908708572387695\n",
      "Test loss: 1.1069509983062744\n",
      "step 8\n",
      "1.2781573650261924\n",
      "Remaining data before / after filtering the learned batch\n",
      "3452\n",
      "3252\n",
      "Starting training:\n",
      "Epoch: 51: Train loss (last batch): 1.3593906164169312, validation loss: 1.013441562652588\n",
      "Best model saved at: model.state\n",
      "Epoch: 52: Train loss (last batch): 0.9417921304702759, validation loss: 1.0099481344223022\n",
      "Best model saved at: model.state\n",
      "Epoch: 53: Train loss (last batch): 0.9773699045181274, validation loss: 1.0344018936157227\n",
      "Epoch: 54: Train loss (last batch): 0.6684784889221191, validation loss: 1.028428554534912\n",
      "Epoch: 55: Train loss (last batch): 0.46160081028938293, validation loss: 1.0423749685287476\n",
      "Test loss: 1.033412218093872\n",
      "Starting training:\n",
      "Epoch: 51: Train loss (last batch): 0.9440658092498779, validation loss: 1.0656908750534058\n",
      "Best model saved at: model.state\n",
      "Epoch: 52: Train loss (last batch): 1.1964144706726074, validation loss: 1.057700753211975\n",
      "Best model saved at: model.state\n",
      "Epoch: 53: Train loss (last batch): 0.7416738867759705, validation loss: 1.0769537687301636\n",
      "Epoch: 54: Train loss (last batch): 0.6342279314994812, validation loss: 1.0637058019638062\n",
      "Epoch: 55: Train loss (last batch): 0.7380937337875366, validation loss: 1.0628786087036133\n",
      "Test loss: 1.0676766633987427\n",
      "step 9\n",
      "1.238697168526423\n",
      "Remaining data before / after filtering the learned batch\n",
      "3252\n",
      "3052\n",
      "Starting training:\n",
      "Epoch: 56: Train loss (last batch): 1.1292697191238403, validation loss: 1.0446393489837646\n",
      "Best model saved at: model.state\n",
      "Epoch: 57: Train loss (last batch): 0.44034045934677124, validation loss: 1.0251669883728027\n",
      "Best model saved at: model.state\n",
      "Epoch: 58: Train loss (last batch): 0.5164992809295654, validation loss: 1.032751202583313\n",
      "Epoch: 59: Train loss (last batch): 0.24869348108768463, validation loss: 1.0182362794876099\n",
      "Best model saved at: model.state\n",
      "Epoch: 60: Train loss (last batch): 0.37373003363609314, validation loss: 1.0427300930023193\n",
      "Test loss: 1.0232443809509277\n",
      "Starting training:\n",
      "Epoch: 56: Train loss (last batch): 1.4621491432189941, validation loss: 1.0792131423950195\n",
      "Best model saved at: model.state\n",
      "Epoch: 57: Train loss (last batch): 0.7178587317466736, validation loss: 1.0389840602874756\n",
      "Best model saved at: model.state\n",
      "Epoch: 58: Train loss (last batch): 0.7196930646896362, validation loss: 1.095894455909729\n",
      "Epoch: 59: Train loss (last batch): 0.6102267503738403, validation loss: 1.0397205352783203\n",
      "Epoch: 60: Train loss (last batch): 1.4276756048202515, validation loss: 1.0749943256378174\n",
      "Test loss: 1.0919307470321655\n"
     ]
    }
   ],
   "source": [
    "# Predict on unlabled data\n",
    "def get_ent(preds):\n",
    "    res = []\n",
    "    for example in preds:\n",
    "        ent = 0\n",
    "        for p in example:\n",
    "            ent += -p * np.log2(p)\n",
    "        res.append(ent)\n",
    "        \n",
    "    return res\n",
    "\n",
    "import random\n",
    "top_n = 200\n",
    "num_steps = range(10)\n",
    "for step in num_steps:\n",
    "    print(\"step {}\".format(step))\n",
    "    pred = trainer_smart.predict(unlabeled_data, decode=True)\n",
    "\n",
    "    outs = [o for p in pred for o in p['meta']]\n",
    "    ent = get_ent(outs)\n",
    "    ent = np.array(ent)\n",
    "    print(ent.mean())\n",
    "    idx = (-ent).argsort()[:top_n]\n",
    "    #print(\"selected examples based on entropy: \")\n",
    "    #print(idx)\n",
    "    filtered = [unlabeled_data[s] for s in idx]\n",
    "    random_d = [unlabeled_data[s] for s in random.sample(range(len(unlabeled_data)), top_n)]\n",
    "\n",
    "    # Update remaining\n",
    "    print(\"Remaining data before / after filtering the learned batch\")\n",
    "    print(len(unlabeled_data))\n",
    "    unlabeled_data = [s for i, s in enumerate(unlabeled_data) if i not in idx]\n",
    "    print(len(unlabeled_data))\n",
    "\n",
    "    #print(random)\n",
    "    #print(filtered)\n",
    "\n",
    "    #Retrain\n",
    "    filtered_encoded = trainer_smart.processor(filtered, data_type='full', list_input= True, as_batches=True)\n",
    "    random_encoded = trainer_smart.processor(random_d, data_type='full', list_input= True, as_batches=True)\n",
    "    res_smart = trainer_smart.train_model([filtered_encoded, val_data, test_data])\n",
    "    res_random = trainer_random.train_model([random_encoded, val_data, test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'during_training': {'1': {'train_loss': 1.0959333181381226,\n",
       "   'val_loss': 1.0971243381500244},\n",
       "  '2': {'train_loss': 1.1127394437789917, 'val_loss': 1.0927706956863403},\n",
       "  '3': {'train_loss': 1.2162951231002808, 'val_loss': 1.0798826217651367},\n",
       "  '4': {'train_loss': 1.1723943948745728, 'val_loss': 1.0638456344604492},\n",
       "  '5': {'train_loss': 1.0028953552246094, 'val_loss': 1.0499619245529175},\n",
       "  '6': {'train_loss': 1.090139627456665, 'val_loss': 1.0430418252944946},\n",
       "  '7': {'train_loss': 0.9486572742462158, 'val_loss': 1.050020694732666},\n",
       "  '8': {'train_loss': 1.1977633237838745, 'val_loss': 1.0444697141647339},\n",
       "  '9': {'train_loss': 1.0246580839157104, 'val_loss': 1.0404095649719238},\n",
       "  '10': {'train_loss': 0.6556094288825989, 'val_loss': 1.0469732284545898},\n",
       "  '11': {'train_loss': 1.0623605251312256, 'val_loss': 1.0581321716308594},\n",
       "  '12': {'train_loss': 0.7871716618537903, 'val_loss': 1.0428305864334106},\n",
       "  '13': {'train_loss': 1.1186940670013428, 'val_loss': 1.0667556524276733},\n",
       "  '14': {'train_loss': 1.3207297325134277, 'val_loss': 1.088484525680542},\n",
       "  '15': {'train_loss': 1.049099326133728, 'val_loss': 1.0591458082199097},\n",
       "  '16': {'train_loss': 1.1189956665039062, 'val_loss': 1.0685073137283325},\n",
       "  '17': {'train_loss': 0.9065014123916626, 'val_loss': 1.056923747062683},\n",
       "  '18': {'train_loss': 1.2434639930725098, 'val_loss': 1.0566821098327637},\n",
       "  '19': {'train_loss': 0.9182854890823364, 'val_loss': 1.0448863506317139},\n",
       "  '20': {'train_loss': 1.1181001663208008, 'val_loss': 1.0406386852264404},\n",
       "  '21': {'train_loss': 0.887336015701294, 'val_loss': 1.0367839336395264},\n",
       "  '22': {'train_loss': 1.700872778892517, 'val_loss': 1.0353449583053589},\n",
       "  '23': {'train_loss': 1.0598227977752686, 'val_loss': 1.037508487701416},\n",
       "  '24': {'train_loss': 0.6425461769104004, 'val_loss': 1.0609575510025024},\n",
       "  '25': {'train_loss': 0.8147274851799011, 'val_loss': 1.057183027267456},\n",
       "  '26': {'train_loss': 1.0146806240081787, 'val_loss': 1.0480296611785889},\n",
       "  '27': {'train_loss': 0.8028432130813599, 'val_loss': 1.0411734580993652},\n",
       "  '28': {'train_loss': 0.8426177501678467, 'val_loss': 1.0547993183135986},\n",
       "  '29': {'train_loss': 1.3315198421478271, 'val_loss': 1.0865635871887207},\n",
       "  '30': {'train_loss': 0.632735550403595, 'val_loss': 1.0776888132095337},\n",
       "  '31': {'train_loss': 1.4126191139221191, 'val_loss': 1.0514800548553467},\n",
       "  '32': {'train_loss': 0.7288591861724854, 'val_loss': 1.0232900381088257},\n",
       "  '33': {'train_loss': 1.1392401456832886, 'val_loss': 1.0322906970977783},\n",
       "  '34': {'train_loss': 1.0369181632995605, 'val_loss': 1.0408066511154175},\n",
       "  '35': {'train_loss': 0.9922736883163452, 'val_loss': 1.0423856973648071},\n",
       "  '36': {'train_loss': 1.0320680141448975, 'val_loss': 1.0291532278060913},\n",
       "  '37': {'train_loss': 1.2148253917694092, 'val_loss': 1.0175738334655762},\n",
       "  '38': {'train_loss': 0.9755659103393555, 'val_loss': 1.0366709232330322},\n",
       "  '39': {'train_loss': 0.6312243342399597, 'val_loss': 1.03802490234375},\n",
       "  '40': {'train_loss': 1.0244741439819336, 'val_loss': 1.081958532333374},\n",
       "  '41': {'train_loss': 0.8066275715827942, 'val_loss': 1.0894639492034912},\n",
       "  '42': {'train_loss': 0.832968533039093, 'val_loss': 1.059286117553711},\n",
       "  '43': {'train_loss': 0.6269853711128235, 'val_loss': 1.0258805751800537},\n",
       "  '44': {'train_loss': 0.8821024894714355, 'val_loss': 1.0154292583465576},\n",
       "  '45': {'train_loss': 0.8464297652244568, 'val_loss': 1.0149935483932495},\n",
       "  '46': {'train_loss': 0.9979891777038574, 'val_loss': 1.013409972190857},\n",
       "  '47': {'train_loss': 1.0384202003479004, 'val_loss': 1.0270806550979614},\n",
       "  '48': {'train_loss': 0.9247334003448486, 'val_loss': 1.009764552116394},\n",
       "  '49': {'train_loss': 0.6837278604507446, 'val_loss': 1.045725703239441},\n",
       "  '50': {'train_loss': 0.789980947971344, 'val_loss': 1.032309651374817},\n",
       "  '51': {'train_loss': 1.3593906164169312, 'val_loss': 1.013441562652588},\n",
       "  '52': {'train_loss': 0.9417921304702759, 'val_loss': 1.0099481344223022},\n",
       "  '53': {'train_loss': 0.9773699045181274, 'val_loss': 1.0344018936157227},\n",
       "  '54': {'train_loss': 0.6684784889221191, 'val_loss': 1.028428554534912},\n",
       "  '55': {'train_loss': 0.46160081028938293, 'val_loss': 1.0423749685287476},\n",
       "  '56': {'train_loss': 1.1292697191238403, 'val_loss': 1.0446393489837646},\n",
       "  '57': {'train_loss': 0.44034045934677124, 'val_loss': 1.0251669883728027},\n",
       "  '58': {'train_loss': 0.5164992809295654, 'val_loss': 1.032751202583313},\n",
       "  '59': {'train_loss': 0.24869348108768463, 'val_loss': 1.0182362794876099},\n",
       "  '60': {'train_loss': 0.37373003363609314, 'val_loss': 1.0427300930023193}},\n",
       " 'best': {'train_loss': 0.24869348108768463, 'val_loss': 1.0182362794876099},\n",
       " 'test': {tensor(1.0232, grad_fn=<DivBackward0>)}}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_smart['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'during_training': {'1': {'train_loss': 0.9932723045349121,\n",
       "   'val_loss': 1.1460973024368286},\n",
       "  '2': {'train_loss': 1.8655883073806763, 'val_loss': 0.9856749773025513},\n",
       "  '3': {'train_loss': 0.5568922758102417, 'val_loss': 0.9643186330795288},\n",
       "  '4': {'train_loss': 0.8071258664131165, 'val_loss': 0.9565287828445435},\n",
       "  '5': {'train_loss': 0.5423922538757324, 'val_loss': 0.9556002020835876},\n",
       "  '6': {'train_loss': 0.9349740743637085, 'val_loss': 0.9569883942604065},\n",
       "  '7': {'train_loss': 1.3021361827850342, 'val_loss': 0.9552294015884399},\n",
       "  '8': {'train_loss': 0.726514458656311, 'val_loss': 0.9544289708137512},\n",
       "  '9': {'train_loss': 1.0989142656326294, 'val_loss': 0.955574095249176},\n",
       "  '10': {'train_loss': 0.4896788001060486, 'val_loss': 0.955385684967041},\n",
       "  '11': {'train_loss': 1.331813097000122, 'val_loss': 0.955652117729187},\n",
       "  '12': {'train_loss': 1.322219729423523, 'val_loss': 0.956355631351471},\n",
       "  '13': {'train_loss': 0.5277446508407593, 'val_loss': 0.9499547481536865},\n",
       "  '14': {'train_loss': 0.9116512537002563, 'val_loss': 0.9504325985908508},\n",
       "  '15': {'train_loss': 0.9161804914474487, 'val_loss': 0.9494937062263489},\n",
       "  '16': {'train_loss': 0.7597208619117737, 'val_loss': 0.9517405033111572},\n",
       "  '17': {'train_loss': 0.8987411260604858, 'val_loss': 0.9483364820480347},\n",
       "  '18': {'train_loss': 0.719573974609375, 'val_loss': 0.947390079498291},\n",
       "  '19': {'train_loss': 0.9619226455688477, 'val_loss': 0.9482828378677368},\n",
       "  '20': {'train_loss': 0.5232361555099487, 'val_loss': 0.9488431811332703},\n",
       "  '21': {'train_loss': 1.098631739616394, 'val_loss': 0.9484428763389587},\n",
       "  '22': {'train_loss': 0.9191515445709229, 'val_loss': 0.9475398063659668},\n",
       "  '23': {'train_loss': 0.9256869554519653, 'val_loss': 0.9500771164894104},\n",
       "  '24': {'train_loss': 0.7456627488136292, 'val_loss': 0.9495823979377747},\n",
       "  '25': {'train_loss': 0.5184981226921082, 'val_loss': 0.951298177242279},\n",
       "  '26': {'train_loss': 1.0890486240386963, 'val_loss': 0.9519614577293396},\n",
       "  '27': {'train_loss': 1.1691080331802368, 'val_loss': 0.9534572958946228},\n",
       "  '28': {'train_loss': 0.8661308884620667, 'val_loss': 0.9515878558158875},\n",
       "  '29': {'train_loss': 1.0989185571670532, 'val_loss': 0.9469677805900574},\n",
       "  '30': {'train_loss': 0.9079446196556091, 'val_loss': 0.9465218782424927},\n",
       "  '31': {'train_loss': 1.2639210224151611, 'val_loss': 0.945889413356781},\n",
       "  '32': {'train_loss': 0.7375331521034241, 'val_loss': 0.9458656311035156},\n",
       "  '33': {'train_loss': 0.5814820528030396, 'val_loss': 0.9450486302375793},\n",
       "  '34': {'train_loss': 0.5351881980895996, 'val_loss': 0.9469635486602783},\n",
       "  '35': {'train_loss': 1.0820927619934082, 'val_loss': 0.9447499513626099},\n",
       "  '36': {'train_loss': 1.0759968757629395, 'val_loss': 0.9451717734336853},\n",
       "  '37': {'train_loss': 0.9299224615097046, 'val_loss': 0.9432560801506042},\n",
       "  '38': {'train_loss': 0.7116551995277405, 'val_loss': 0.944229781627655},\n",
       "  '39': {'train_loss': 0.9142112731933594, 'val_loss': 0.9436624646186829},\n",
       "  '40': {'train_loss': 0.8875399231910706, 'val_loss': 0.9461364150047302},\n",
       "  '41': {'train_loss': 1.1118757724761963, 'val_loss': 0.9531173706054688},\n",
       "  '42': {'train_loss': 1.0626928806304932, 'val_loss': 0.9455386996269226},\n",
       "  '43': {'train_loss': 0.8824523091316223, 'val_loss': 0.9486888647079468},\n",
       "  '44': {'train_loss': 0.6935596466064453, 'val_loss': 0.9515203237533569},\n",
       "  '45': {'train_loss': 0.9065508842468262, 'val_loss': 0.9455541372299194},\n",
       "  '46': {'train_loss': 1.103534460067749, 'val_loss': 0.9430764317512512},\n",
       "  '47': {'train_loss': 0.6294281482696533, 'val_loss': 0.9455287456512451},\n",
       "  '48': {'train_loss': 0.9337501525878906, 'val_loss': 0.9440619349479675}},\n",
       " 'best': {'train_loss': 1.103534460067749, 'val_loss': 0.9430764317512512},\n",
       " 'test': {tensor(0.9291, grad_fn=<DivBackward0>)}}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_random['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inp': ['مواطن فرنسي يواجه المحاكمة في القدس لتهريبه أسلحة ',\n",
       "   'فرنسي يفلت من المحاكمة في القدس<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>'],\n",
       "  'label': [['disagree']],\n",
       "  'mask': [1],\n",
       "  'out': [[-0.16341207921504974, 0.45698094367980957, -0.5681448578834534]],\n",
       "  'pred': [['other']],\n",
       "  'meta': [[0.28354206681251526, 0.527291476726532, 0.18916653096675873]]},\n",
       " {'inp': ['مواطن فرنسي يواجه المحاكمة في القدس لتهريبه أسلحة ',\n",
       "   'فرنسي يفلت من المحاكمة في القدس<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>'],\n",
       "  'label': [['disagree']],\n",
       "  'mask': [1],\n",
       "  'out': [[-0.16341206431388855, 0.45698079466819763, -0.5681449174880981]],\n",
       "  'pred': [['other']],\n",
       "  'meta': [[0.28354209661483765, 0.527291476726532, 0.18916653096675873]]}]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent.argmax()\n",
    "ent[idx[100]]\n",
    "ent[ent.argmax()]\n",
    "unlabeled_data[idx[100]]\n",
    "trainer_random.predict([unlabeled_data[idx[100]], unlabeled_data[idx[100]]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
